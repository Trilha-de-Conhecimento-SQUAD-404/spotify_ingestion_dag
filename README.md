# DAG de ingest√£o de dados

Esse reposit√≥rio cont√©m o c√≥digo para execu√ß√£o de uma DAG (Directed Acyclic Graph), orquestrada pelo Apache Airflow, respons√°vel por realizar a ingest√£o de m√∫sicas de uma playlist do Spotify para um banco de dados PostgreSQL.

Acesse nossos recursos: üîó

- [Engenharia de Dados](./wiki/engenharia_dados.md)
- [Exemplo de uso da DAG](./wiki/dag_ingestao.md)

## Estrutrura do projeto

- `dags:` arquivo da DAG
- `wiki:` recursos de documenta√ß√£o do pipeline
- `airflow_variables.json`: vari√°veis de ambiente para serem importadas no Airflow
- `docker-compose.yaml:` configura√ß√£o Docker para execu√ß√£o do Apache Airflow no Docker

## Pr√©-requisitos

Antes de executar esta aplica√ß√£o, √© necess√°rio garantir que voc√™ tenha os seguintes pr√©-requisitos instalados:

- Python (vers√£o 3.11.0 ou superior)
- Docker (vers√£o 24.0.6 ou superior)
- Docker-compose (vers√£o 2.21.0-desktop.1 ou superior)
- PostgreSQL (vers√£o 15 ou superior)
- Conta de desenvolvedor no Spotify para acesso √† API - [documenta√ß√£o SpotifyAPI](https://developer.spotify.com/)

## Como Executar

Siga os passos abaixo para executar a aplica√ß√£o:

1. Clone este reposit√≥rio

   ```
   git clone https://github.com/AnaJuliaMM/comite_2602.git
   ```

2. Crie um arquivo `.env` na raiz do projeto e insira a seguinte configura√ß√£o:

   ```
   AIRFLOW_UID=5000
   ```

3. Inicie o Apache Airflow
   ```
   docker-compose up -d
   ```
4. Acesse a interface gr√°fica do Apache Airflow em `localhost:8080`

5. Crie um banco de dados no PostgreSQL

6. No arquivo `airflow_variables.json` insira os valores das vari√°veis de acordo com seu contexto

7. Na se√ß√£o _Variables_ da interface, fa√ßa a o upload do arquivo e a importa√ß√£o das vari√°veis de ambiente

8. Mude o status da DAG para ativo e execute o pipeline

## Resultado esperado

Visualize os dados inseridos no banco de dados ‚ú®

![Captura de tela 2024-02-26 105852](https://github.com/AnaJuliaMM/comite_2602/assets/123522605/29ab1cc4-0843-4711-85f7-7edf9ff1d55c)
