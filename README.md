# DAG de ingest√£o de dados

Esse reposit√≥rio cont√©m o c√≥digo para execu√ß√£o de uma DAG (Directed Acyclic Graph), orquestrada pelo Apache Airflow, respons√°vel por realizar a ingest√£o de m√∫sicas de uma playlist do Spotify para um banco de dados PostgreSQL.


## 1. Landscape
Antes de executar esta aplica√ß√£o, √© necess√°rio garantir que voc√™ tenha as seguintes tecnologias instaladss:

- Python (vers√£o 3.11.0 ou superior)
- Docker (vers√£o 24.0.6 ou superior)
- Docker-compose (vers√£o 2.21.0-desktop.1 ou superior)
- PostgreSQL (vers√£o 15 ou superior)
- Conta de desenvolvedor no Spotify para acesso √† API - [documenta√ß√£o SpotifyAPI](https://developer.spotify.com/)


## 2. Pr√©-requisitos do projeto
- Docker Preparado com as tecnologias
- Todas tecnologias adjacentes com suas vers√µes especificadas 
- Dados mocks necess√°rios disponiveis 
- Emula√ß√£o de Network baseada na realidade 
- Garantir que todo pr√©-requesito necess√°rio esteja liberado no nosso chocolatey

## 3. Como fazer o setup
### **Vari√°veis**
### Airflow Connection (interface)

1. Crie um banco de dados no PostgreSQL

2. Na se√ß√£o **Admin >> Connections**, crie uma conex√£o

```
Connection Id= local_postgres
Connection Type= Postgres
Host = (servidor do banco de dados)
Database = (nome do banco de dados) 
Login = (usu√°rio do banco de dados)
Password = (senha do banco de dados)
Port = (porta do servidor)
```

### Airflow Variables (interface)
1. No arquivo `airflow_variables.json` insira os valores das vari√°veis de acordo com seu contexto

2. Na se√ß√£o **Admin >> Connections**, fa√ßa a o upload do arquivo e a importa√ß√£o das vari√°veis de ambiente


## Passo a passo:

Siga os passos abaixo para executar a aplica√ß√£o:

### Iniciar Apache Airflow com Docker

1. Clone este reposit√≥rio

   ```
   git clone https://github.com/AnaJuliaMM/comite_2602.git
   ```

2. Crie um arquivo `.env` na raiz do projeto e insira a seguinte configura√ß√£o:

   ```
   AIRFLOW_UID=5000
   ```

3. Inicie o Apache Airflow

   ```
   docker-compose up -d
   ```

4. Acesse a interface gr√°fica do Apache Airflow em `localhost:8080`

### Execu√ß√£o
 Mude o status da DAG para ativo e execute o pipeline!

### Esse Lab tem o objetivo de:
- Aprender sobre diferentes origens e destino de dados
- Realizar um Pipeline completo de ingest√£o 
- Aprender sobre processo Batch e schedulagem
- Instanciar ferramentas
- Versionamento de c√≥digo na pr√°tica
- Documenta√ß√£o 

## Estrutrura do projeto

- `dags:` arquivo da DAG
- `wiki:` recursos de documenta√ß√£o do pipeline
- `airflow_variables.json`: vari√°veis de ambiente para serem importadas no Airflow
- `docker-compose.yaml:` configura√ß√£o Docker para execu√ß√£o do Apache Airflow no Docker




## Resultado esperado

Visualize os dados inseridos no banco de dados ‚ú®

![Captura de tela 2024-02-26 105852](https://github.com/AnaJuliaMM/comite_2602/assets/123522605/29ab1cc4-0843-4711-85f7-7edf9ff1d55c)

Acesse nossos recursos: üîó

- [Engenharia de Dados](./wiki/engenharia_dados.md)
- [Exemplo de uso da DAG](./wiki/dag_ingestao.md)